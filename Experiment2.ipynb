{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras_helper import NNWeightHelper\n",
    "from snes import SNES\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from dataSet import dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use just a small sample of the train set to test\n",
    "SAMPLE_SIZE = 1024\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 93\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mobile_phone': 0, 'paper_notebook': 1, 'back_pack': 2, 'monitor': 3, 'projector': 4, 'calculator': 5, 'desk_lamp': 6, 'laptop_computer': 7, 'speaker': 8, 'letter_tray': 9, 'bike': 10, 'trash_can': 11, 'printer': 12, 'stapler': 13, 'headphones': 14, 'punchers': 15, 'file_cabinet': 16, 'tape_dispenser': 17, 'mouse': 18, 'pen': 19, 'bookcase': 20, 'desk_chair': 21, 'desktop_computer': 22, 'ruler': 23, 'mug': 24, 'phone': 25, 'scissors': 26, 'ring_binder': 27, 'bike_helmet': 28, 'bottle': 29, 'keyboard': 30}\n"
     ]
    }
   ],
   "source": [
    "Amazon_path = './Original_images/amazon/images'\n",
    "dslr_path   = './Original_images/dslr/images'\n",
    "webcam_path = './Original_images/webcam/images'\n",
    "paths = [Amazon_path, dslr_path, webcam_path]\n",
    "files = os.listdir(Amazon_path)\n",
    "labels = {}\n",
    "count  = 0\n",
    "for key in files:\n",
    "    a = {key : count}\n",
    "    labels.update(a)\n",
    "    count += 1\n",
    "print (labels)\n",
    "\n",
    "images_path = []\n",
    "Amazon = dataSet()\n",
    "dslr   = dataSet()\n",
    "webcam = dataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for dirname in files:\n",
    "    images_name = os.listdir(Amazon_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = Amazon_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        Amazon.upData(image_data, labels[dirname], labels)        \n",
    "\n",
    "Amazon.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2817, 2352)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for dirname in files:\n",
    "    images_name = os.listdir(dslr_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = dslr_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        dslr.upData(image_data, labels[dirname], labels)\n",
    "dslr.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for dirname in files:\n",
    "    images_name = os.listdir(webcam_path + '/' + dirname)\n",
    "    for name in images_name:\n",
    "        Image_Path = webcam_path + '/' + dirname + '/' + name\n",
    "        images_path.append(Image_Path)\n",
    "        image_data = cv2.imread(Image_Path)\n",
    "        image_data = cv2.resize(image_data, (img_rows, img_cols), interpolation=cv2.INTER_CUBIC)\n",
    "        image_data = image_data.reshape(img_rows, img_cols, 3)\n",
    "        webcam.upData(image_data, labels[dirname], labels)\n",
    "webcam.sHape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2817, 2352)\n",
      "x_test shape: (498, 2352)\n",
      "2817 train samples\n",
      "498 test samples\n",
      "Total number of weights to evolve is: (111562,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (2817, 2352)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26e7f760ccfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-26e7f760ccfb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total number of weights to evolve is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mall_examples_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-26e7f760ccfb>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (2817, 2352)"
     ]
    }
   ],
   "source": [
    "def train_classifier(model, X, y):\n",
    "    X_features = model.predict(X)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_features, y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "def predict_classifier(model, clf, X):\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "# Load Amazon for target data\n",
    "x_train = Amazon.data\n",
    "y_train = Amazon.label\n",
    "\n",
    "# load DSLR for source data\n",
    "x_test = dslr.data\n",
    "y_test = dslr.label\n",
    "\n",
    "#domain data\n",
    "x_train_domain = np.concatenate((x_train,x_test), axis=0)\n",
    "y_train_domain = np.concatenate((np.zeros(x_train.shape[0]), np.ones(x_test.shape[0])),axis=0)\n",
    "\n",
    "# x_test_domain = np.concatenate((x_test1,mnistm_test), axis=0)# totaly 20000 sample\n",
    "# y_test_domain = np.concatenate((np.zeros(x_test1.shape[0]), np.ones(mnistm_test.shape[0])),axis=0)\n",
    "#print(x_test_domain.shape)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#one hot encode outputs\n",
    "#y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "#y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "#bu hocanÄ±n ki\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# this is irrelevant for what we want to achieve\n",
    "#model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "# print(\"compilation is over\")\n",
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()\n",
    "\n",
    "def main():\n",
    "    print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "    all_examples_indices = list(range(x_train.shape[0]))\n",
    "    clf, _ = train_classifier(model, x_train, y_train)\n",
    "    y_pred = predict_classifier(model, clf, x_test)\n",
    "    print(y_test.shape, y_pred.shape)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Non-trained NN Test accuracy:', test_accuracy)\n",
    "    # print('Test MSE:', test_mse)\n",
    "\n",
    "    snes = SNES(weights, 1, POPULATION_SIZE)\n",
    "    for i in range(0, GENERATIONS):\n",
    "        start = timer()\n",
    "        asked = snes.ask()\n",
    "\n",
    "        # to be provided back to snes\n",
    "        told = []\n",
    "\n",
    "        # use a small number of training samples for speed purposes\n",
    "        subsample_indices = np.random.choice(all_examples_indices, size=SAMPLE_SIZE, replace=False)\n",
    "        # evaluate on another subset\n",
    "        subsample_indices_valid = np.random.choice(all_examples_indices, size=SAMPLE_SIZE + 1, replace=False)\n",
    "\n",
    "        # iterate over the population\n",
    "        for asked_j in asked:\n",
    "            # set nn weights\n",
    "            nnw.set_weights(asked_j)\n",
    "            # train the classifer and get back the predictions on the training data\n",
    "            clf, _ = train_classifier(model, x_train[subsample_indices], y_train[subsample_indices])\n",
    "            clf2, _ = train_classifier(model, x_train_domain[subsample_indices], y_train_domain[subsample_indices])\n",
    "\n",
    "            # calculate the predictions on a different set\n",
    "            y_pred = predict_classifier(model, clf, x_train[subsample_indices_valid])\n",
    "            # score = accuracy_score(y_train[subsample_indices_valid], y_pred)\n",
    "            loss_lab = mean_squared_error(y_train[subsample_indices_valid], y_pred)\n",
    "            \n",
    "            y_pred2 = predict_classifier(model, clf2, x_train_domain[subsample_indices_valid])\n",
    "            score2 = accuracy_score(y_train_domain[subsample_indices_valid], y_pred2)\n",
    "            loss_dom = mean_squared_error(y_train_domain[subsample_indices_valid], y_pred)\n",
    "            # clf, _ = train_classifier(model, x_train, y_train)\n",
    "            # y_pred = predict_classifier(model, clf, x_test)\n",
    "            # score = accuracy_score(y_test, y_pred)\n",
    "            # append to array of values that are to be returned\n",
    "            #inverted = (-score2)\n",
    "            total_loss = (loss_lab + (2*-loss_dom))# change this functions\n",
    "\n",
    "            told.append(total)\n",
    "\n",
    "        snes.tell(asked, told)\n",
    "        end = timer()\n",
    "        print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "\n",
    "    nnw.set_weights(snes.center)\n",
    "\n",
    "    clf, _ = train_classifier(model, x_train, y_train)\n",
    "    y_pred = predict_classifier(model, clf, x_test)\n",
    "\n",
    "\n",
    "    print(y_test.shape, y_pred.shape)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
