{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this main code by Ssamot from https://github.com/ssamot/infoGA/blob/master/mnist_snes_example.py\n",
    "# plot loss function from https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "# converting MNIST into 3 dimentional from Rabia Yasa Kostas (1700421)/\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras_helper import NNWeightHelper\n",
    "from keras.utils import np_utils\n",
    "from snes import SNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use just a small sample of the train set to test\n",
    "SAMPLE_SIZE = 500\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 15\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X, y):\n",
    "    X_features = model.predict(X)\n",
    "    clf = RandomForestClassifier(n_estimators = 10)\n",
    "    clf.fit(X_features, y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "\n",
    "\n",
    "def predict_classifier(model, clf, X):\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from keras for source domain\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1).astype(np.uint8) * 255\n",
    "x_train = np.concatenate([x_train, x_train, x_train], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST-M dataset for target domain\n",
    "mnistm = pkl.load(open('mnistm_data.pkl', 'rb'))\n",
    "mnistm_train = mnistm['train']\n",
    "mnistm_test = mnistm['test']\n",
    "mnistm_valid = mnistm['valid']\n",
    "x_test=mnistm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create part data for domain classifier, combination from source and target data\n",
    "x_domain=np.concatenate((x_train,x_test), axis =0)\n",
    "y_domain = np.concatenate((np.zeros(y_train.shape[0]), np.ones(y_test.shape[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation is over\n"
     ]
    }
   ],
   "source": [
    "# neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80, activation='relu'))\n",
    "\n",
    "# this is irrelevant for what we want to achieve\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "print(\"compilation is over\")\n",
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights to evolve is: (756752,)\n",
      "Non-trained NN Test accuracy: 0.1731\n",
      "Step 1.0 : -2.590818363273453 best: -2.590818363273453 15\n",
      "It took 25.036049601971172 seconds to complete generation 1\n",
      "Step 2.0 : -2.5548902195608783 best: -2.5548902195608783 15\n",
      "It took 23.37602155096829 seconds to complete generation 2\n",
      "Step 3.0 : -2.5848303393213574 best: -2.5548902195608783 15\n",
      "It took 24.437216817983426 seconds to complete generation 3\n",
      "Step 4.0 : -2.5768463073852295 best: -2.5548902195608783 15\n",
      "It took 36.09608659497462 seconds to complete generation 4\n",
      "Step 5.0 : -2.5409181636726546 best: -2.5409181636726546 15\n",
      "It took 32.308545045903884 seconds to complete generation 5\n",
      "Step 6.0 : -2.5508982035928143 best: -2.5409181636726546 15\n",
      "It took 32.64923382306006 seconds to complete generation 6\n",
      "Step 7.0 : -2.536926147704591 best: -2.536926147704591 15\n",
      "It took 31.416449278010987 seconds to complete generation 7\n",
      "Step 8.0 : -2.5708582834331337 best: -2.536926147704591 15\n",
      "It took 33.344139175023884 seconds to complete generation 8\n",
      "Step 9.0 : -2.568862275449102 best: -2.536926147704591 15\n",
      "It took 37.213112525991164 seconds to complete generation 9\n",
      "Step 10.0 : -2.536926147704591 best: -2.536926147704591 15\n",
      "It took 33.21489751606714 seconds to complete generation 10\n",
      "Step 11.0 : -2.538922155688623 best: -2.536926147704591 15\n",
      "It took 39.97088882303797 seconds to complete generation 11\n",
      "Step 12.0 : -2.5808383233532934 best: -2.536926147704591 15\n",
      "It took 43.74621245008893 seconds to complete generation 12\n",
      "Step 13.0 : -2.5588822355289422 best: -2.536926147704591 15\n",
      "It took 46.917899338994175 seconds to complete generation 13\n",
      "Step 14.0 : -2.530938123752495 best: -2.530938123752495 15\n",
      "It took 25.425589073915035 seconds to complete generation 14\n",
      "Step 15.0 : -2.520958083832335 best: -2.520958083832335 15\n",
      "It took 29.198098868946545 seconds to complete generation 15\n",
      "Step 16.0 : -2.506986027944112 best: -2.506986027944112 15\n",
      "It took 34.08591962396167 seconds to complete generation 16\n",
      "Step 17.0 : -2.5429141716566868 best: -2.506986027944112 15\n",
      "It took 32.81455502891913 seconds to complete generation 17\n",
      "Step 18.0 : -2.5469061876247503 best: -2.506986027944112 15\n",
      "It took 35.575861010933295 seconds to complete generation 18\n",
      "Step 19.0 : -2.5189620758483033 best: -2.506986027944112 15\n",
      "It took 34.96625708299689 seconds to complete generation 19\n",
      "Step 20.0 : -2.50499001996008 best: -2.50499001996008 15\n",
      "It took 42.63031261891592 seconds to complete generation 20\n",
      "Step 21.0 : -2.5269461077844313 best: -2.50499001996008 15\n",
      "It took 45.62053983297665 seconds to complete generation 21\n",
      "Step 22.0 : -2.5229540918163673 best: -2.50499001996008 15\n",
      "It took 39.3147884500213 seconds to complete generation 22\n",
      "Step 23.0 : -2.528942115768463 best: -2.50499001996008 15\n",
      "It took 47.61380283907056 seconds to complete generation 23\n",
      "Step 24.0 : -2.479041916167665 best: -2.479041916167665 15\n",
      "It took 41.15860387298744 seconds to complete generation 24\n",
      "Step 25.0 : -2.4830339321357284 best: -2.479041916167665 15\n",
      "It took 44.08262650598772 seconds to complete generation 25\n",
      "Step 26.0 : -2.471057884231537 best: -2.471057884231537 15\n",
      "It took 47.04580511304084 seconds to complete generation 26\n",
      "Step 27.0 : -2.4850299401197606 best: -2.471057884231537 15\n",
      "It took 44.991451520938426 seconds to complete generation 27\n",
      "Step 28.0 : -2.5229540918163673 best: -2.471057884231537 15\n",
      "It took 44.414057037909515 seconds to complete generation 28\n",
      "Step 29.0 : -2.49500998003992 best: -2.471057884231537 15\n",
      "It took 39.538553121034056 seconds to complete generation 29\n",
      "Step 30.0 : -2.506986027944112 best: -2.471057884231537 15\n",
      "It took 39.58869220898487 seconds to complete generation 30\n",
      "Step 31.0 : -2.499001996007984 best: -2.471057884231537 15\n",
      "It took 39.441344262100756 seconds to complete generation 31\n",
      "Step 32.0 : -2.4550898203592815 best: -2.4550898203592815 15\n",
      "It took 40.109691338962875 seconds to complete generation 32\n",
      "Step 33.0 : -2.5189620758483033 best: -2.4550898203592815 15\n",
      "It took 39.90625796606764 seconds to complete generation 33\n",
      "Step 34.0 : -2.5129740518962076 best: -2.4550898203592815 15\n",
      "It took 40.06165319203865 seconds to complete generation 34\n",
      "Step 35.0 : -2.502994011976048 best: -2.4550898203592815 15\n",
      "It took 39.15542852401268 seconds to complete generation 35\n",
      "Step 36.0 : -2.4770459081836327 best: -2.4550898203592815 15\n",
      "It took 37.790459137992 seconds to complete generation 36\n",
      "Step 37.0 : -2.4810379241516967 best: -2.4550898203592815 15\n",
      "It took 39.13364430598449 seconds to complete generation 37\n",
      "Step 38.0 : -2.497005988023952 best: -2.4550898203592815 15\n",
      "It took 38.66928471904248 seconds to complete generation 38\n",
      "Step 39.0 : -2.500998003992016 best: -2.4550898203592815 15\n",
      "It took 42.52635821304284 seconds to complete generation 39\n",
      "Step 40.0 : -2.489021956087824 best: -2.4550898203592815 15\n",
      "It took 44.98885205597617 seconds to complete generation 40\n",
      "Step 41.0 : -2.4810379241516967 best: -2.4550898203592815 15\n",
      "It took 45.65600847103633 seconds to complete generation 41\n",
      "Step 42.0 : -2.4830339321357284 best: -2.4550898203592815 15\n",
      "It took 45.56340121291578 seconds to complete generation 42\n",
      "Step 43.0 : -2.4770459081836327 best: -2.4550898203592815 15\n",
      "It took 44.313256724970415 seconds to complete generation 43\n",
      "Step 44.0 : -2.471057884231537 best: -2.4550898203592815 15\n",
      "It took 49.854035682976246 seconds to complete generation 44\n",
      "Step 45.0 : -2.4830339321357284 best: -2.4550898203592815 15\n",
      "It took 53.039416905958205 seconds to complete generation 45\n",
      "Step 46.0 : -2.4850299401197606 best: -2.4550898203592815 15\n",
      "It took 52.96315335505642 seconds to complete generation 46\n",
      "Step 47.0 : -2.4510978043912175 best: -2.4510978043912175 15\n",
      "It took 45.74555433297064 seconds to complete generation 47\n",
      "Step 48.0 : -2.4451097804391217 best: -2.4451097804391217 15\n",
      "It took 56.94571790494956 seconds to complete generation 48\n",
      "Step 49.0 : -2.4910179640718564 best: -2.4451097804391217 15\n",
      "It took 58.14840081206057 seconds to complete generation 49\n",
      "Step 50.0 : -2.4570858283433132 best: -2.4451097804391217 15\n",
      "It took 57.36910950904712 seconds to complete generation 50\n",
      "Test accuracy on target: 0.1582\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "all_examples_indices = list(range(x_train.shape[0]))\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)\n",
    "# print('Test MSE:', test_mse)\n",
    "\n",
    "snes = SNES(weights, 1, POPULATION_SIZE)\n",
    "log = []\n",
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "\n",
    "    # to be provided back to snes\n",
    "    told = []\n",
    "\n",
    "    # use a small number of training samples for speed purposes\n",
    "    subsample_indices = np.random.choice(all_examples_indices, size=SAMPLE_SIZE, replace=False)\n",
    "    # evaluate on another subset\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices, size=SAMPLE_SIZE + 1, replace=False)\n",
    "\n",
    "    # iterate over the population\n",
    "    for asked_j in asked:\n",
    "        # set nn weights\n",
    "        nnw.set_weights(asked_j)\n",
    "        # train the label classifer and get back the predictions on the training data\n",
    "        clf, _ = train_classifier(model, x_train[subsample_indices], y_train[subsample_indices])\n",
    "        # train the domain classifier and get back the predictions on the training data\n",
    "        clf2, _ = train_classifier(model, x_domain[subsample_indices], y_domain[subsample_indices])\n",
    "\n",
    "        # calculate the label predictions on a different set\n",
    "        y_pred = predict_classifier(model, clf, x_train[subsample_indices_valid])\n",
    "        score = accuracy_score(y_train[subsample_indices_valid], y_pred)\n",
    "\n",
    "        # calculate the domain predictions on a different set\n",
    "        y_pred2 = predict_classifier(model, clf2, x_domain[subsample_indices_valid])\n",
    "        score2 = accuracy_score(y_domain[subsample_indices_valid], y_pred2)\n",
    "        \n",
    "        # weighted score to give back to snes\n",
    "        total = (score+(3*-score2))\n",
    "        told.append(total)\n",
    "\n",
    "    temp = snes.tell(asked, told)\n",
    "    log.append(temp)\n",
    "    end = timer()\n",
    "    print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "    \n",
    "nnw.set_weights(snes.center)\n",
    "\n",
    "# predict on target data\n",
    "clf, _ = train_classifier(model, x_train, y_train)\n",
    "y_pred = predict_classifier(model, clf, x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Test accuracy on target:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAH1lJREFUeJzt3XmcHVWd9/HPlyQkQULIxhIaSCSMGlBRW3gcZETZUQwqKjM4RkXRcRsHQcKAsujMBNSB8XGZJ6JDxEFkecTwuERAcFBHpBNxIChm1XTYQjYSMEDg9/xxTkPlcm/3TbpuV1/6+3697qur6px76neqqu+vtltXEYGZmVl/7VB1AGZm9vzghGJmZqVwQjEzs1I4oZiZWSmcUMzMrBROKGZmVgonlAYkrZB0ZNVxAEgKSdP68f5jJF1fckz7SNokaViZ7VrrSTpcUneL5+HtY5CR9DFJF7VyHk4ozyOS3iPp53WK/gmYXagXkh6SNLwwbUSe1tQXkyLiTxGxc0Q8tZ0x2SDl7aP/JJ0v6dsVzr/eTsPXgVMk7daq+TqhPM9JejUwNiJ+VVO0DjiuMH5cnmYlKX4gtyFvHxVqxbYTEZuBHwHvLrvt4kz8qvMCVgBH5uGRwKXAffl1KTAyl00E/h+wHlgL3AbskMvOAlYBG4F7gSMazOty4N+BG3PdnwH7FsoDmJaHxwLfAlYDfwTOJe0YvATYDDwFbALW5/qfAS6rmV/k911TmHYtcE7aJJ6ZdivwWeAXOa6fABNz2ZTczvA8/h5gWa63HDilUUx1+v9e4Hf5vcuADxbKGi7fOu38G7ASeARYABzWy/o9Hrgnz3MVcEah7APAkjy/ecDken0uLKP3F5bBL4BLgDXA5wrt9fTvHuCVefpk4Lq8LpcDH+8l3jcCv8l9WwmcXyjriWsm8CfgYeCcQvlo0ja2Ls//TKC7l3kNtu3jcKAb+BTwEHA/cGJeh3/I6+kft3PZjQK+ndfXeuAOYPcG7cwClhbW41sa1DsWeAJ4Mvfrt01s5z19PAt4ALgiT/9U7u99wPvZ+rNgJPCFvM4fJH2GjAZeAPwZeDrPfxPPbsOnALe07HOzVQ23+4utE8qFwK+A3YBJwC+Bz+ayf8krckR+HQYIeFHeeIsfRvs1mNfleSP7q7yR/Bvw80J5cSP6FvB9YExu8w/AqbnsPcX35WnXAGfWTAvgwLwR7gqMy8MH8twPjKXAX+QN9VZgdqE/AQzPG/AjwIty2Z7AAY1iqtP/NwL75eX2OuAxnv3Qrbt8G7TzLmBCjumT+R9zVIO695MTTu5/z/zeQPpAfmVeF/8b+K/aPtcso2JC2QJ8LMcwGng7KWG9OvdvGrAvaSdgASnh7wi8kPQhc0yDeA8HXprf97K8vk6sievreZ4vBx4HXpLLZ5MS8Xhgb+Bu+k4og2n7ODwv18/kbeADpCR8Jen/4ADSB+jU7Vh2HwRuAHYChgGvAnZp0M7bSTsBOwDvBB4F9mxQ93zg29uwnff08SLSdjealJgeyP3biZT4ip8Fl5B2eMbn5XAD8C+F9p6zjknb9dqWfW62quF2f7F1QlkKHF8oOwZYkYcvJH3AT6t5/zTS3tSRwIg+5nU5cFVhfGfSXtveeTxye8NIez7TC3U/CNyah5/zz0k66vlQzbSe9i7L7/8Q6cNoGs/9wDi3MP5h4Md5eApbf2CsB94GjK6Z13NiamLZXw/8fW/Lt8l21gEvb1D2p9z3XWqmfwO4uGZdPJn7+0yfa5ZRMaH8qaa9+T19qZl+SJ26ZwP/0WTfLgUuqVkXHYXyXwMn5+FlwLGFstPoO6EMmu2D9OH4Z2BYHh+T2z6kUGcBOUls47J7H2kH8WXbsX3dCcxoUHY+NQmlj+38cNL/9qhC+TfJCSKPTyusG5ES2n6F8tcAywvt1Uso+wNPbWtfm335GkpzJpNOL/X4Y54G8HnS6ZGfSFomaRZARCwBPkHasB6SdJWkyTS2smcgIjaRDuNr608k7aHVxrJXL+2uI/0D1vMt0vnUd+fheh4oDD9G+oDdSkQ8Stpj+xBwv6QfSHpxLzFtRdJxkn4laa2k9aRTGRNzcd3l26CdMyT9TtKG3M7YQju13pbn80dJP5P0mjx9q3Wd18Uael/GRStrxvcm7ZDU2heYLGl9zwv4R2D3Bn07RNItklZL2kBa1rV9a7SuJtfEVdx+ejPg20fh7rBNkjYVitbEsxf4/5z/Plgo/3O9eec2e1t2V5CS/lWS7pN0saQRDdp5t6Q7C+vrQBpvX/Xe39t2DrA60nWOHrXrrTg8iXTUsqAQz4/z9N6MATY0G/O2ckJpzn2kD4Ae++RpRMTGiPhkRLwQeDNwuqQjctmVEfHa/N4gHc42snfPgKSdSYex99XUeZi0t1wby6o8HHXa/R/SKYl6biOdftgd6NedNhExPyKOyu39nrRH2yimZ0gaSbqO8AXSuetdgR+S9sB6Xb417RxGOt/8DmBcbmdDTzt14r0jImaQTmNeD1ydi7Za15JeQDqNtoq0RwjpH7nHHrVN14yvJJ3mqLWStDe5a+E1JiKOrxcv6fTOPNJR61jSacC6favjfgrbF2mbacaAbx/x7N1hO0dE3QSxHRouu4h4MiIuiIjpwF8Cb6LORWtJ++aYPwpMyNvX3TReB1v1q6/tvN57SOutozBeXIcPk5LoAYXtZ2xhmTX6v3sJ8NsGZf3mhNKc7wDnSpokaSLpXO63ASS9SdI0SSJ9gD0FPC3pRZLekDekzTx7kayR4yW9VtKOpAudv4qIrfZ28x7a1cA/SRqTN/LTe2Ih7bF15DZ6/JB0vvY5Ih0DnwC8OQ9vF0m7S5qRP3wfJ10E7OlrvZiKdiSdM14NbJF0HHB0oe26y7dOO2NI56BXA8MlfQbYpUG8O0o6RdLYiHiSdH6/p83vAO+VdFBed/8M3B4RKyJiNSmxvEvSMEnvo36yKLoMOEPSq5RMy+vt18BGSWdJGp3bOzDflVfPGNK5782SDgb+po/5Fl0NnC1pnKQO0jWePg2S7aMMDZedpNdLeqnS92UeIe2w1du+XkD6kF6d3/de0hFKIw8CUyT1fMb2up03cDVpW3yJpJ2AT/cURMTTpAR3Sc9twJL2knRMYf4TJI2tafN1pDu9WsIJpTmfA7pIe/t3AQvzNEjnJG8i/ZP8N/DViLiFtPHMJu1JPEDaEz67l3lcCZxHOtX1KtIF5no+RtpTXkbaa7ySdK4V4KfAIuABSQ8DRMRCYIOkQ+o1FhGLImJRL3E1YwdSYrsvx/864O8axVQz/43Ax0n/POtI/+zzClUaLd9a80mH/H8gndLZzHNPPxX9LbBC0iOkUyCn5HhuIv3jXkfaQ9wPOLnwvg+Q7pJaQ7pY+ste5kFEXEP6HtCVpBsvrgfG552DNwEHke56epiUfGo/AHp8GLhQ0kbSDs3VDerVcwFpmSwn3Yl1RbNvrHr7KElvy24P0h1sj5DuwPoZdZZPRNwDfJG0DT5Iusj/i17meU3+u0bSwia28+eIiB8BXwJuIZ327bn1//H896ye6Xk7vol0MxAR8XvSztGyfEpssqRRpNNsc3ubb3+oHzseVhJJl5MuoJ3bovaPBj4cESe2on0zaz1JLyGdZhsZEVu24/0fI532+1TpwfXMwwmleq1OKGbWniS9hXTaeifSkcXTg3nH0Ke8zMwGrw+Svn6wlHT98O96r14tH6GYmVkpfIRiZmalaOeH122ziRMnxpQpU6oOw8ysrSxYsODhiOjrS5NDK6FMmTKFrq6uqsMwM2srkpp6uoJPeZmZWSmcUMzMrBROKGZmVoohdQ2lnieffJLu7m42b97cd+UBNmrUKDo6Ohgxou7DT83MBpUhn1C6u7sZM2YMU6ZMIT1/cHCICNasWUN3dzdTp06tOhwzsz4N+VNemzdvZsKECYMqmQBIYsKECYPyyMnMrJ4hn1CAQZdMegzWuMzM6nFCMTOzUjihVGz9+vV89atfrToMM7N+c0KpmBOKmT1fOKFUbNasWSxdupSDDjqIM888s+pwzMy225C/bbjoghsWcc99j5Ta5vTJu3DeCQc0LJ89ezZ33303d955Z6nzNTMbaD5CMTOzUvgIpaC3IwkzM+udj1AqNmbMGDZu3Fh1GGZm/eaEUrEJEyZw6KGHcuCBB/qivJm1NZ/yGgSuvPLKqkMwM+s3H6GYmVkpnFDMzKwUTiikR8UPRoM1LjOzeoZ8Qhk1ahRr1qwZdB/ePb+HMmrUqKpDMTNrypC/KN/R0UF3dzerV6+uOpTn6PnFRjOzdjDkE8qIESP8i4hmZiUY8qe8zMysHE4oZmZWikoTiqRjJd0raYmkWXXKR0r6bi6/XdKUmvJ9JG2SdMZAxWxmZvVVllAkDQO+AhwHTAf+WtL0mmqnAusiYhpwCXBRTfm/Aj9qdaxmZta3Ko9QDgaWRMSyiHgCuAqYUVNnBjA3D18LHCFJAJJOBJYDiwYoXjMz60WVCWUvYGVhvDtPq1snIrYAG4AJknYGzgIu6Gsmkk6T1CWpazDeGmxm9nzRrhflzwcuiYhNfVWMiDkR0RkRnZMmTWp9ZGZmQ1SV30NZBexdGO/I0+rV6ZY0HBgLrAEOAU6SdDGwK/C0pM0R8eXWh21mZvVUmVDuAPaXNJWUOE4G/qamzjxgJvDfwEnATyM9I+WwngqSzgc2OZmYmVWrsoQSEVskfRSYDwwDvhkRiyRdCHRFxDzgG8AVkpYAa0lJx8zMBiENtocitlJnZ2d0dXVVHYaZWVuRtCAiOvuq164X5c3MbJBxQjEzs1I4oZiZWSmcUMzMrBROKGZmVgonFDMzK4UTipmZlcIJxczMSuGEYmZmpXBCMTOzUjihmJlZKZxQzMysFE4oZmZWCicUMzMrhROKmZmVwgnFzMxK4YRiZmalcEIxM7NSOKGYmVkpnFDMzKwUTihmZlYKJxQzMyuFE4qZmZXCCcXMzErhhGJmZqVwQjEzs1I4oZiZWSmcUMzMrBROKGZmVgonFDMzK0WlCUXSsZLulbRE0qw65SMlfTeX3y5pSp5+lKQFku7Kf98w0LGbmdnWKksokoYBXwGOA6YDfy1pek21U4F1ETENuAS4KE9/GDghIl4KzASuGJiozcyskSqPUA4GlkTEsoh4ArgKmFFTZwYwNw9fCxwhSRHxm4i4L09fBIyWNHJAojYzs7qqTCh7ASsL4915Wt06EbEF2ABMqKnzNmBhRDzeojjNzKwJw6sOoD8kHUA6DXZ0L3VOA04D2GeffQYoMjOzoafKI5RVwN6F8Y48rW4dScOBscCaPN4BfA94d0QsbTSTiJgTEZ0R0Tlp0qQSwzczs6IqE8odwP6SpkraETgZmFdTZx7pojvAScBPIyIk7Qr8AJgVEb8YsIjNzKyhyhJKvibyUWA+8Dvg6ohYJOlCSW/O1b4BTJC0BDgd6Lm1+KPANOAzku7Mr90GuAtmZlagiKg6hgHT2dkZXV1dVYdhZtZWJC2IiM6+6vmb8mZmVgonFDMzK4UTipmZlcIJxczMSuGEYmZmpXBCMTOzUjihmJlZKZxQzMysFE4oZmZWCicUMzMrhROKmZmVoqmEImlfSUfm4dGSxrQ2LDMzazd9JhRJHyD9/O7/yZM6gOtbGZSZmbWfZo5QPgIcCjwCEBGLAT8q3szMttJMQnk8Ip7oGcm/nDh0nnlvZmZNaSah/EzSPwKjJR0FXAPc0NqwzMys3TSTUGYBq4G7gA8CPwTObWVQZmbWfob3VSEinga+nl9mZmZ19ZlQJC2nzjWTiHhhSyIyM7O21GdCAYq/IzwKeDswvjXhmJlZu+rzGkpErCm8VkXEpcAbByA2MzNrI82c8nplYXQH0hFLM0c2ZmY2hDSTGL5YGN4CrADe0ZJozMysbTVzl9frByIQMzNrbw0TiqTTe3tjRPxr+eGYmVm76u0IxU8UNjOzpjVMKBFxwUAGYmZm7a2Zu7xGAacCB5C+hwJARLyvhXGZmVmbaeZZXlcAewDHAD8j/R7KxlYGZWZm7aeZhDItIj4NPBoRc0lfajyktWGZmVm7aSahPJn/rpd0IDAW/8CWmZnVaCahzJE0Dvg0MA+4B7iojJlLOlbSvZKWSJpVp3ykpO/m8tslTSmUnZ2n3yvpmDLiMTOz7dfMN+X/IyKeIl0/Ke0Jw5KGAV8BjgK6gTskzYuIewrVTgXWRcQ0SSeTEtk7JU0HTibdKDAZuEnSX+Q4zcysAs0coSyXNEfSEZJU4rwPBpZExLL8E8NXATNq6swA5ubha4GeGGYAV0XE4xGxHFiS2zMzs4o0k1BeDNwEfARYIenLkl5bwrz3AlYWxrvztLp1ImILsAGY0OR7AZB0mqQuSV2rV68uIWwzM6unmcfXPxYRV0fEW4GDgF1Ip7/aQkTMiYjOiOicNGlS1eGYmT1vNXOEgqTXSfoqsID05cYynja8Cti7MN6Rp9WtI2k46Q6zNU2+18zMBlCfCUXSCuATwG3ASyPiHRFxXQnzvgPYX9JUSTuSLrLPq6kzD5iZh08CfhoRkaefnO8CmwrsD/y6hJjMzGw7NXOX18si4pGyZxwRWyR9FJgPDAO+GRGLJF0IdEXEPOAbwBWSlgBrSUmHXO9q0i3MW4CP+A4vM7NqKe3wDw2dnZ3R1dVVdRhmZm1F0oKI6OyrXlPXUMzMzPrihGJmZqVo5qL830vaRck3JC2UdPRABGdmZu2jmSOU9+WL8kcD44C/BWa3NCozM2s7zSSUnsetHA9cERGLCtPMzMyA5hLKAkk/ISWU+ZLGAE+3NiwzM2s3zXwP5VTSI1eWRcRjksYD721tWGZm1m6aOUJ5DXBvRKyX9C7gXNJDGs3MzJ7RTEL5GvCYpJcDnwSWAt9qaVRmZtZ2mkkoW/Lzs2YAX46IrwBjWhuWmZm1m2auoWyUdDbpduHDJO0AjGhtWGZm1m6aOUJ5J/A46fsoD5AeFf/5lkZlZmZtp5kf2HoA+E9grKQ3AZsjwtdQzMxsK808euUdpN8aeTvph7Vul3RSqwMzM7P20sw1lHOAV0fEQwCSJpF+Y/7aVgZmZmbtpZlrKDv0JJNsTZPvMzOzIaSZI5QfS5oPfCePvxP4YetCMjOzdtRnQomIMyW9DTg0T5oTEd9rbVhmZtZumjlCISKuA65rcSxmZtbGGiYUSRuBej84LyAiYpeWRWVmZm2nYUKJCD9exczMmua7tczMrBROKGZmVgonFDMzK4UTipmZlcIJxczMSuGEYmZmpXBCMTOzUjihmJlZKZxQzMysFJUkFEnjJd0oaXH+O65BvZm5zmJJM/O0nST9QNLvJS2SNHtgozczs3qqOkKZBdwcEfsDN+fxrUgaD5wHHAIcDJxXSDxfiIgXA68ADpV03MCEbWZmjVSVUGYAc/PwXODEOnWOAW6MiLURsQ64ETg2Ih6LiFsAIuIJYCHQMQAxm5lZL6pKKLtHxP15+AFg9zp19gJWFsa787RnSNoVOIF0lGNmZhVq6vdQtoekm4A96hSdUxyJiJBU7zH5fbU/nPQrkl+KiGW91DsNOA1gn3322dbZmJlZk1qWUCLiyEZlkh6UtGdE3C9pT+ChOtVWAYcXxjuAWwvjc4DFEXFpH3HMyXXp7Ozc5sRlZmbNqeqU1zxgZh6eCXy/Tp35wNGSxuWL8UfnaUj6HDAW+MQAxGpmZk2oKqHMBo6StBg4Mo8jqVPSZQARsRb4LHBHfl0YEWsldZBOm00HFkq6U9L7q+iEmZk9SxFD5yxQZ2dndHV1VR2GmVlbkbQgIjr7qudvypuZWSmcUMzMrBROKGZmVgonFDMzK4UTipmZlcIJxczMSuGEYmZmpXBCMTOzUjihmJlZKZxQzMysFE4oZmZWCicUMzMrhROKmZmVwgnFzMxK4YRiZmalcEIxM7NSOKGYmVkpnFDMzKwUTihmZlYKJxQzMyuFE4qZmZXCCcXMzErhhGJmZqVwQjEzs1I4oZiZWSmcUMzMrBROKGZmVgonFDMzK4UTipmZlcIJxczMSuGEYmZmpagkoUgaL+lGSYvz33EN6s3MdRZLmlmnfJ6ku1sfsZmZ9aWqI5RZwM0RsT9wcx7fiqTxwHnAIcDBwHnFxCPprcCmgQnXzMz6UlVCmQHMzcNzgRPr1DkGuDEi1kbEOuBG4FgASTsDpwOfG4BYzcysCVUllN0j4v48/ACwe506ewErC+PdeRrAZ4EvAo/1NSNJp0nqktS1evXqfoRsZma9Gd6qhiXdBOxRp+ic4khEhKTYhnYPAvaLiH+QNKWv+hExB5gD0NnZ2fR8zMxs27QsoUTEkY3KJD0oac+IuF/SnsBDdaqtAg4vjHcAtwKvATolrSDFv5ukWyPicMzMrDJVnfKaB/TctTUT+H6dOvOBoyWNyxfjjwbmR8TXImJyREwBXgv8wcnEzKx6VSWU2cBRkhYDR+ZxJHVKugwgItaSrpXckV8X5mlmZjYIKWLoXFbo7OyMrq6uqsMwM2srkhZERGdf9fxNeTMzK4UTipmZlcIJxczMSuGEYmZmpXBCMTOzUjihmJlZKZxQzMysFE4oZmZWCicUMzMrhROKmZmVwgnFzMxK4YRiZmalcEIxM7NSOKGYmVkpnFDMzKwUTihmZlYKJxQzMyuFE4qZmZXCCcXMzErhhGJmZqVwQjEzs1I4oZiZWSmcUMzMrBROKGZmVgpFRNUxDBhJq4E/Vh3HNpoIPFx1EAPMfR4a3Of2sW9ETOqr0pBKKO1IUldEdFYdx0Byn4cG9/n5x6e8zMysFE4oZmZWCieUwW9O1QFUwH0eGtzn5xlfQzEzs1L4CMXMzErhhGJmZqVwQhkEJI2XdKOkxfnvuAb1ZuY6iyXNrFM+T9LdrY+4//rTZ0k7SfqBpN9LWiRp9sBGv20kHSvpXklLJM2qUz5S0ndz+e2SphTKzs7T75V0zEDG3R/b22dJR0laIOmu/PcNAx379ujPOs7l+0jaJOmMgYq5JSLCr4pfwMXArDw8C7ioTp3xwLL8d1weHlcofytwJXB31f1pdZ+BnYDX5zo7ArcBx1Xdpwb9HAYsBV6YY/0tML2mzoeBf8/DJwPfzcPTc/2RwNTczrCq+9TiPr8CmJyHDwRWVd2fVva3UH4tcA1wRtX96c/LRyiDwwxgbh6eC5xYp84xwI0RsTYi1gE3AscCSNoZOB343ADEWpbt7nNEPBYRtwBExBPAQqBjAGLeHgcDSyJiWY71KlLfi4rL4lrgCEnK06+KiMcjYjmwJLc32G13nyPiNxFxX56+CBgtaeSARL39+rOOkXQisJzU37bmhDI47B4R9+fhB4Dd69TZC1hZGO/O0wA+C3wReKxlEZavv30GQNKuwAnAza0IsgR99qFYJyK2ABuACU2+dzDqT5+L3gYsjIjHWxRnWba7v3ln8CzgggGIs+WGVx3AUCHpJmCPOkXnFEciIiQ1fS+3pIOA/SLiH2rPy1atVX0utD8c+A7wpYhYtn1R2mAk6QDgIuDoqmNpsfOBSyJiUz5gaWtOKAMkIo5sVCbpQUl7RsT9kvYEHqpTbRVweGG8A7gVeA3QKWkFaX3uJunWiDicirWwzz3mAIsj4tISwm2VVcDehfGOPK1ene6cJMcCa5p872DUnz4jqQP4HvDuiFja+nD7rT/9PQQ4SdLFwK7A05I2R8SXWx92C1R9EcevAPg8W1+gvrhOnfGk86zj8ms5ML6mzhTa56J8v/pMul50HbBD1X3po5/DSTcTTOXZC7YH1NT5CFtfsL06Dx/A1hfll9EeF+X70+ddc/23Vt2PgehvTZ3zafOL8pUH4FdAOnd8M7AYuKnwodkJXFao9z7ShdklwHvrtNNOCWW7+0zaAwzgd8Cd+fX+qvvUS1+PB/5AuhPonDztQuDNeXgU6Q6fJcCvgRcW3ntOft+9DNI72crsM3Au8Ghhvd4J7FZ1f1q5jgtttH1C8aNXzMysFL7Ly8zMSuGEYmZmpXBCMTOzUjihmJlZKZxQzMysFE4oZm1A0ick7VQY/2F+7IzZoOHbhs0GgfygQEXE0w3KVwCdEfHwgAZmtg18hGLWC0mfzr9z8XNJ35F0hqT9JP04/17HbZJenOteLulLkn4paZmkk/L0nSXdLGlh/p2PGXn6lNz2t4C7gb0lfU1SV/6dlwtyvY8Dk4FbJN2Sp62QNDEPny7p7vz6RKHt30n6em7rJ5JGD/TysyGm6m9W+uXXYH0BryZ9U3sUMIb0rf4zSN/w3z/XOQT4aR6+nPRt6B1Iv2WyJE8fDuyShyeSvi0t0pMNngb+V2GePU8MGEZ6btnL8vgKYGKh3orc1quAu4AXADuTHoH+itz2FuCgXP9q4F1VL1O/nt8vPxzSrLFDge9HxGZgs6QbSMnlL4FrCk+HLf5ex/WRTlvdI6nnkfwC/lnSX5ESyF48+7j+P0bErwrvf4ek00hJaE9SYvqfXmJ8LfC9iHgUQNL/BQ4D5gHLI+LOXG8BKcmYtYwTitm22QFYHxEHNSgv/nZHT8Y5BZgEvCoinszXQ0blskefqSxNJR0BvToi1km6vFBvexRjeQrwKS9rKV9DMWvsF8AJkkblH0J6E+lHzJZLejuki+mSXt5HO2OBh3IyeT2wb4N6u5ASzIZ8dHNcoWwj6bRbrduAEyXtJOkFwFvyNLMB5yMUswYi4g5J80innB4kXavYQDri+Jqkc4ERpJ98/W0vTf0ncIOku4Au4PcN5vdbSb/J5StJCa3HHODHku6LiNcX3rMwH8n8Ok+6LCJ+M9h+bM2GBt82bNYLSTtH+jW9nYD/Ak6LiIVVx2U2GPkIxax3cyRNJ13LmOtkYtaYj1DMzKwUvihvZmalcEIxM7NSOKGYmVkpnFDMzKwUTihmZlaK/w9tb+mYPyUXiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Plot the loss for each generation\n",
    "plt.plot(log)\n",
    "plt.title('loss plot(Mnist as a source and Mnist-m as a target)')\n",
    "plt.xlabel('genaration')\n",
    "plt.ylabel('loss value')\n",
    "plt.legend('test', loc='upper left')\n",
    "plt.savefig('Plot_mnist_mnistm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
